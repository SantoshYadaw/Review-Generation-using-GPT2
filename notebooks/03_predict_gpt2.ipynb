{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de514552-34a4-4189-b277-5585f55c2891",
   "metadata": {},
   "source": [
    "# 03 - Predict using GPT2 Model\n",
    "\n",
    "This notebook contains the steps to use the trained gpt2 model from the previous steps for prediction\n",
    "\n",
    "Author:\n",
    "- Santosh Yadaw\n",
    "- santoshyadawprl@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee987b2a-3429-4988-b2e8-f3289c151302",
   "metadata": {},
   "source": [
    "## a. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65f88d7f-65f2-4e7e-af03-d3503b72c7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import random\n",
    "import logging\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "# import spacy\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88549d53-5824-4487-81d2-d7515a88d4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fc12fb4-d04d-4e04-9535-7f984692ac71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "logger.info(f\"device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef1a1873-2d7e-44cd-932e-b426fc1ab66d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:HOME_PATH: /home/jupyter/text-gen\n",
      "INFO:root:SPLIT_DATA_PATH: /home/jupyter/text-gen/data/processed/split_data.csv\n",
      "INFO:root:model_path: /home/jupyter/text-gen/models\n"
     ]
    }
   ],
   "source": [
    "# Constants\n",
    "HOME_PATH = os.path.split(os.getcwd())[0]\n",
    "logger.info(f\"HOME_PATH: {HOME_PATH}\")\n",
    "\n",
    "SPLIT_DATA_PATH = os.path.join(HOME_PATH,\"data\",\"processed\",\"split_data.csv\")\n",
    "logger.info(f\"SPLIT_DATA_PATH: {SPLIT_DATA_PATH}\")\n",
    "\n",
    "# Set the path to save gpt2 model\n",
    "MODEL_PATH = os.path.join(HOME_PATH, \"models\")\n",
    "logger.info(f\"model_path: {MODEL_PATH}\")\n",
    "\n",
    "# GPT Inference constants\n",
    "MAX_LENGTH= 100\n",
    "NUM_RETURN_SEQUENCE= 1\n",
    "NO_REPEAT_NGRAM_SIZE= 2\n",
    "REPETITION_PENALTY= 1.5\n",
    "TOP_P= 0.92\n",
    "TEMPERATURE=.85\n",
    "DO_SAMPLE= True\n",
    "TOP_K= 125\n",
    "EARLY_STOPPING= True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b92942d3-a673-49a5-9360-e03ae81c5ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9147/2089933622.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_val[\"text\"] = data_val[\"text\"].astype(str)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42218</th>\n",
       "      <td>bought media room great faster previous version</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42219</th>\n",
       "      <td>second kindle would lost without convenient th...</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42220</th>\n",
       "      <td>got wife loves easy read loves fact carry book</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42221</th>\n",
       "      <td>every year never run</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42222</th>\n",
       "      <td>works great watching tv shows plugged right ea...</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text split\n",
       "42218    bought media room great faster previous version   val\n",
       "42219  second kindle would lost without convenient th...   val\n",
       "42220     got wife loves easy read loves fact carry book   val\n",
       "42221                               every year never run   val\n",
       "42222  works great watching tv shows plugged right ea...   val"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Validation data\n",
    "data = pd.read_csv(SPLIT_DATA_PATH)\n",
    "data_val = data[data[\"split\"] == \"val\"]\n",
    "data_val[\"text\"] = data_val[\"text\"].astype(str)\n",
    "data_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8a1dca9-b3c3-460b-a776-af6998313716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading trained model and tokenizer\n",
    "gpt2_model = GPT2LMHeadModel.from_pretrained(MODEL_PATH)\n",
    "gpt2_tokenizer = GPT2Tokenizer.from_pretrained(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b99c13c-cdd9-4b38-ba69-68cce348e38d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01561737060546875,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 4691,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d71d0bcbe828403bb0114f873a31a38d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4691 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9147/151377263.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_val[\"trunc_text\"] = data_val[\"text\"].progress_apply(lambda x: truncate_text(x))\n"
     ]
    }
   ],
   "source": [
    "# Prep data for inference by taking away original sentence all words except 2-3 words randomly\n",
    "def truncate_text(text: str):\n",
    "    \n",
    "    ran_num = random.randint(5,10)\n",
    "    ran_num = 4\n",
    "    \n",
    "    # Split by space\n",
    "    text_list_split = text.split(\" \")\n",
    "    \n",
    "    # Select randomly 2-4 words to retain\n",
    "    text_list_trunc = text_list_split[:ran_num]\n",
    "    \n",
    "    # Return\n",
    "    return \" \".join(text_list_trunc)\n",
    "\n",
    "data_val[\"trunc_text\"] = data_val[\"text\"].progress_apply(lambda x: truncate_text(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9990408-e41b-4dc5-a9b6-198870421d69",
   "metadata": {},
   "source": [
    "## b. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6414828-0012-4832-842f-f61d98878f3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.010198116302490234,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 4691,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2446fdd395ea411ebadb4e2d484f9ef9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4691 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9147/4033951604.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_val[\"gpt_text_gen\"] = res\n"
     ]
    }
   ],
   "source": [
    "# Generate inference\n",
    "\n",
    "# Create a list for trunc text\n",
    "trunc_list = data_val[\"trunc_text\"].to_list()\n",
    "\n",
    "def get_inference_gpt2(text: str):\n",
    "    # Encode the text using tokenizer\n",
    "    text_ids = gpt2_tokenizer.encode(text, return_tensors = 'pt')\n",
    "    \n",
    "    generated_text_samples = gpt2_model.generate(\n",
    "    text_ids, \n",
    "    max_length= MAX_LENGTH,  \n",
    "    num_return_sequences= NUM_RETURN_SEQUENCE,\n",
    "    no_repeat_ngram_size=NO_REPEAT_NGRAM_SIZE ,\n",
    "    repetition_penalty=REPETITION_PENALTY,\n",
    "    top_p=TOP_P,\n",
    "    temperature=TEMPERATURE,\n",
    "    do_sample= DO_SAMPLE,\n",
    "    top_k= TOP_K,\n",
    "    early_stopping= EARLY_STOPPING)\n",
    "\n",
    "    return gpt2_tokenizer.decode(generated_text_samples[0], skip_special_tokens=True)\n",
    "\n",
    "# Get res\n",
    "res = []\n",
    "\n",
    "for review in tqdm(trunc_list):\n",
    "    res.append(get_inference_gpt2(review))\n",
    "    \n",
    "    \n",
    "# Add back to original dataframe\n",
    "data_val[\"gpt_text_gen\"] = res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a90f41-068b-4ddf-ba62-ac9301e312a4",
   "metadata": {},
   "source": [
    "## c. Evaluation\n",
    "\n",
    "- Jaccard similarity\n",
    "- Cross Encoder: Measure of how sysmantically similar are the output of the model and reference answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35d220e-5434-491c-bf5b-41435ad9ec2b",
   "metadata": {},
   "source": [
    "### i. Jaccard Similarity\n",
    "\n",
    "Jaccard similarity coefficient basically treats the data objects like sets. It is defined as the size of the intersection of two sets divide by the size of the union. We use this as a way to measure how many words that is generated by gpt2 is identical to the original words in the sentence. The higher the ratio means the more similar the words are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d12f377-1a18-4641-a74f-84385a894b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function\n",
    "def jaccard_similarity(x,y):\n",
    "    \"\"\" returns the jaccard similarity between two lists \"\"\"\n",
    "    intersection_cardinality = len(set.intersection(*[set(x), set(y)]))\n",
    "    union_cardinality = len(set.union(*[set(x), set(y)]))\n",
    "    \n",
    "    return intersection_cardinality/float(union_cardinality)\n",
    "\n",
    "def corpus(text):\n",
    "    text_list = text.split()\n",
    "    return text_list\n",
    "\n",
    "def count_words(text_list: str):\n",
    "    # text_list_format = ast.literal_eval(text_list)\n",
    "    return len(text_list)\n",
    "\n",
    "# Printing some examples\n",
    "def view_generated_samples(index: int, data: pd.DataFrame):  \n",
    "    index = index\n",
    "    # original_text = (\" \").join(ast.literal_eval(data.iloc[index][\"text_lists\"]))\n",
    "    original_text = (\" \").join(data.iloc[index][\"text_lists\"])\n",
    "    print(f\"Original text: {original_text}\")\n",
    "    input_words = data.iloc[index][\"trunc_text\"]\n",
    "    print(f\"input_words: {input_words}\")\n",
    "    gpt2_text = data.iloc[index][\"gpt_text_gen\"]\n",
    "    print(f\"gpt2_text generated: {gpt2_text}\")\n",
    "    print(f\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2cf72f08-9179-49b8-86f1-89690d2c1d47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004927396774291992,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 4691,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8557e8da4ccf4d16a61aa777c32c55cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4691 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9147/541998252.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_val[\"jaccard_score\"] = data_val.progress_apply(lambda x: jaccard_similarity(x[\"text\"],x[\"gpt_text_gen\"]),axis=1)\n"
     ]
    }
   ],
   "source": [
    "# Calculate jaccard similarity\n",
    "data_val[\"jaccard_score\"] = data_val.progress_apply(lambda x: jaccard_similarity(x[\"text\"],x[\"gpt_text_gen\"]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "edfdf853-01a3-4afe-9d47-ec5e82b95e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004661083221435547,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 4691,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3504b22b14ee4b6cafce9bf2b9a87145",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4691 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9147/3535808263.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_val[\"text_lists\"] = data_val[\"text\"].progress_apply(corpus)\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004523277282714844,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 4691,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6a394ef8ebf49f497ca7bb828e39119",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4691 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9147/3535808263.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_val[\"word_count\"] = data_val[\"text_lists\"].progress_apply(count_words)\n"
     ]
    }
   ],
   "source": [
    "# Split the original text into list of words then count\n",
    "data_val[\"text_lists\"] = data_val[\"text\"].progress_apply(corpus)\n",
    "data_val[\"word_count\"] = data_val[\"text_lists\"].progress_apply(count_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "909a07f7-64f8-48c2-a203-a9c1137d3afa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jaccard_score</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4691.000000</td>\n",
       "      <td>4691.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.806629</td>\n",
       "      <td>14.312300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.128142</td>\n",
       "      <td>15.933587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.055556</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.727273</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.809524</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.888889</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>401.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       jaccard_score   word_count\n",
       "count    4691.000000  4691.000000\n",
       "mean        0.806629    14.312300\n",
       "std         0.128142    15.933587\n",
       "min         0.055556     1.000000\n",
       "25%         0.727273     7.000000\n",
       "50%         0.809524    10.000000\n",
       "75%         0.888889    16.000000\n",
       "max         1.000000   401.000000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write down results using Jaccard\n",
    "data_val.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9e50a1-2f7f-49f8-bf36-dd824622a0cc",
   "metadata": {},
   "source": [
    "#### Explore samples with higher than average jaccard similiarity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a8861d88-d059-4112-8e29-ab54d1d9ae03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>split</th>\n",
       "      <th>trunc_text</th>\n",
       "      <th>gpt_text_gen</th>\n",
       "      <th>jaccard_score</th>\n",
       "      <th>text_lists</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42219</th>\n",
       "      <td>second kindle would lost without convenient th...</td>\n",
       "      <td>val</td>\n",
       "      <td>second kindle would lost</td>\n",
       "      <td>second kindle would lost without kindles kinde...</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>[second, kindle, would, lost, without, conveni...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42226</th>\n",
       "      <td>gave echo 5 stars like amazon products ultimat...</td>\n",
       "      <td>val</td>\n",
       "      <td>gave echo 5 stars</td>\n",
       "      <td>gave echo 5 stars could take little bit time f...</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>[gave, echo, 5, stars, like, amazon, products,...</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42227</th>\n",
       "      <td>love pricing quality always buy amazon batteries</td>\n",
       "      <td>val</td>\n",
       "      <td>love pricing quality always</td>\n",
       "      <td>love pricing quality always order</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>[love, pricing, quality, always, buy, amazon, ...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42229</th>\n",
       "      <td>tablet makes reading watching video enjoyable</td>\n",
       "      <td>val</td>\n",
       "      <td>tablet makes reading watching</td>\n",
       "      <td>tablet makes reading watching shows easy enjoy</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>[tablet, makes, reading, watching, video, enjo...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42230</th>\n",
       "      <td>great device amazon way go great quality shows</td>\n",
       "      <td>val</td>\n",
       "      <td>great device amazon way</td>\n",
       "      <td>great device amazon way go great streaming vid...</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>[great, device, amazon, way, go, great, qualit...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46902</th>\n",
       "      <td>bit skeptical first purchasing device roku gla...</td>\n",
       "      <td>val</td>\n",
       "      <td>bit skeptical first purchasing</td>\n",
       "      <td>bit skeptical first purchasing amazonbasics pr...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>[bit, skeptical, first, purchasing, device, ro...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46903</th>\n",
       "      <td>wife loves neat works info endless music optio...</td>\n",
       "      <td>val</td>\n",
       "      <td>wife loves neat works</td>\n",
       "      <td>wife loves neat works videos well amazon prime</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>[wife, loves, neat, works, info, endless, musi...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46905</th>\n",
       "      <td>always happy amazon didnt disappoint work grea...</td>\n",
       "      <td>val</td>\n",
       "      <td>always happy amazon didnt</td>\n",
       "      <td>always happy amazon didnt disappoint job great...</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>[always, happy, amazon, didnt, disappoint, wor...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46906</th>\n",
       "      <td>im giving three stars havent used much watch s...</td>\n",
       "      <td>val</td>\n",
       "      <td>im giving three stars</td>\n",
       "      <td>im giving three stars instead five seems silly...</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>[im, giving, three, stars, havent, used, much,...</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46907</th>\n",
       "      <td>bought kids really love</td>\n",
       "      <td>val</td>\n",
       "      <td>bought kids really love</td>\n",
       "      <td>bought kids really love easy use</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[bought, kids, really, love]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2384 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text split  \\\n",
       "42219  second kindle would lost without convenient th...   val   \n",
       "42226  gave echo 5 stars like amazon products ultimat...   val   \n",
       "42227   love pricing quality always buy amazon batteries   val   \n",
       "42229      tablet makes reading watching video enjoyable   val   \n",
       "42230     great device amazon way go great quality shows   val   \n",
       "...                                                  ...   ...   \n",
       "46902  bit skeptical first purchasing device roku gla...   val   \n",
       "46903  wife loves neat works info endless music optio...   val   \n",
       "46905  always happy amazon didnt disappoint work grea...   val   \n",
       "46906  im giving three stars havent used much watch s...   val   \n",
       "46907                            bought kids really love   val   \n",
       "\n",
       "                           trunc_text  \\\n",
       "42219        second kindle would lost   \n",
       "42226               gave echo 5 stars   \n",
       "42227     love pricing quality always   \n",
       "42229   tablet makes reading watching   \n",
       "42230         great device amazon way   \n",
       "...                               ...   \n",
       "46902  bit skeptical first purchasing   \n",
       "46903           wife loves neat works   \n",
       "46905       always happy amazon didnt   \n",
       "46906           im giving three stars   \n",
       "46907         bought kids really love   \n",
       "\n",
       "                                            gpt_text_gen  jaccard_score  \\\n",
       "42219  second kindle would lost without kindles kinde...       0.904762   \n",
       "42226  gave echo 5 stars could take little bit time f...       0.807692   \n",
       "42227                  love pricing quality always order       0.818182   \n",
       "42229     tablet makes reading watching shows easy enjoy       0.952381   \n",
       "42230  great device amazon way go great streaming vid...       0.809524   \n",
       "...                                                  ...            ...   \n",
       "46902  bit skeptical first purchasing amazonbasics pr...       0.833333   \n",
       "46903     wife loves neat works videos well amazon prime       0.809524   \n",
       "46905  always happy amazon didnt disappoint job great...       0.863636   \n",
       "46906  im giving three stars instead five seems silly...       0.875000   \n",
       "46907                   bought kids really love easy use       1.000000   \n",
       "\n",
       "                                              text_lists  word_count  \n",
       "42219  [second, kindle, would, lost, without, conveni...          13  \n",
       "42226  [gave, echo, 5, stars, like, amazon, products,...          43  \n",
       "42227  [love, pricing, quality, always, buy, amazon, ...           7  \n",
       "42229  [tablet, makes, reading, watching, video, enjo...           6  \n",
       "42230  [great, device, amazon, way, go, great, qualit...           8  \n",
       "...                                                  ...         ...  \n",
       "46902  [bit, skeptical, first, purchasing, device, ro...          22  \n",
       "46903  [wife, loves, neat, works, info, endless, musi...          10  \n",
       "46905  [always, happy, amazon, didnt, disappoint, wor...           9  \n",
       "46906  [im, giving, three, stars, havent, used, much,...          34  \n",
       "46907                       [bought, kids, really, love]           4  \n",
       "\n",
       "[2384 rows x 7 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample those with higher than average jaccard similarity score\n",
    "mean_score = data_val.describe()[\"jaccard_score\"][\"mean\"]\n",
    "data_val_higher_jac_score = data_val[data_val[\"jaccard_score\"] > mean_score]\n",
    "data_val_higher_jac_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa732c92-8482-44c1-9bbd-70378f087452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jaccard_score</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2384.000000</td>\n",
       "      <td>2384.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.903722</td>\n",
       "      <td>12.459732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.069567</td>\n",
       "      <td>11.757412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.807692</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.842105</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.888889</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>159.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       jaccard_score   word_count\n",
       "count    2384.000000  2384.000000\n",
       "mean        0.903722    12.459732\n",
       "std         0.069567    11.757412\n",
       "min         0.807692     1.000000\n",
       "25%         0.842105     6.000000\n",
       "50%         0.888889     9.000000\n",
       "75%         1.000000    14.000000\n",
       "max         1.000000   159.000000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the statistics\n",
    "data_val_higher_jac_score.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "056bd98b-57c1-409b-820a-974272afdabf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: second kindle would lost without convenient throw purse take along wherever go love\n",
      "input_words: second kindle would lost\n",
      "gpt2_text generated: second kindle would lost without kindles kindel best purchase ive made dont know missing\n",
      "\n",
      "\n",
      "Original text: good kids looking reasonable cost\n",
      "input_words: good kids looking reasonable\n",
      "gpt2_text generated: good kids looking reasonable cost tablet works well\n",
      "\n",
      "\n",
      "Original text: bought kids really love\n",
      "input_words: bought kids really love\n",
      "gpt2_text generated: bought kids really love easy use\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Look at some samples\n",
    "view_generated_samples(0, data_val_higher_jac_score)\n",
    "view_generated_samples(10, data_val_higher_jac_score)\n",
    "view_generated_samples(-1, data_val_higher_jac_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bda6f86-dff4-4c5c-a076-252af9448330",
   "metadata": {},
   "source": [
    "#### Explore samples with lower than average jaccard similiarity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6087caff-76a4-479f-b618-adf72837cad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>split</th>\n",
       "      <th>trunc_text</th>\n",
       "      <th>gpt_text_gen</th>\n",
       "      <th>jaccard_score</th>\n",
       "      <th>text_lists</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42218</th>\n",
       "      <td>bought media room great faster previous version</td>\n",
       "      <td>val</td>\n",
       "      <td>bought media room great</td>\n",
       "      <td>bought media room great sound wanted</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>[bought, media, room, great, faster, previous,...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42220</th>\n",
       "      <td>got wife loves easy read loves fact carry book</td>\n",
       "      <td>val</td>\n",
       "      <td>got wife loves easy</td>\n",
       "      <td>got wife loves easy use simple set</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>[got, wife, loves, easy, read, loves, fact, ca...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42221</th>\n",
       "      <td>every year never run</td>\n",
       "      <td>val</td>\n",
       "      <td>every year never run</td>\n",
       "      <td>every year never run batteries great price</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>[every, year, never, run]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42222</th>\n",
       "      <td>works great watching tv shows plugged right ea...</td>\n",
       "      <td>val</td>\n",
       "      <td>works great watching tv</td>\n",
       "      <td>works great watching tv shows netflix amazon p...</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>[works, great, watching, tv, shows, plugged, r...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42223</th>\n",
       "      <td>know bluetooth think auxiliary port older spea...</td>\n",
       "      <td>val</td>\n",
       "      <td>know bluetooth think auxiliary</td>\n",
       "      <td>know bluetooth think auxiliary port since tabl...</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>[know, bluetooth, think, auxiliary, port, olde...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46896</th>\n",
       "      <td>seems like quality varies batts work great las...</td>\n",
       "      <td>val</td>\n",
       "      <td>seems like quality varies</td>\n",
       "      <td>seems like quality varies based needs use</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>[seems, like, quality, varies, batts, work, gr...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46899</th>\n",
       "      <td>easy setup use like picture screen bought 5 ga...</td>\n",
       "      <td>val</td>\n",
       "      <td>easy setup use like</td>\n",
       "      <td>easy setup use like asking weather traffic etc</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>[easy, setup, use, like, picture, screen, boug...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46900</th>\n",
       "      <td>duds bought christmas could stick toys one wor...</td>\n",
       "      <td>val</td>\n",
       "      <td>duds bought christmas could</td>\n",
       "      <td>duds bought christmas couldnt happier</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>[duds, bought, christmas, could, stick, toys, ...</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46904</th>\n",
       "      <td>features old rca tablet memory battery power p...</td>\n",
       "      <td>val</td>\n",
       "      <td>features old rca tablet</td>\n",
       "      <td>features old rca tablet different brands amazo...</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>[features, old, rca, tablet, memory, battery, ...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46908</th>\n",
       "      <td>like bigger screen size allows read books with...</td>\n",
       "      <td>val</td>\n",
       "      <td>like bigger screen size</td>\n",
       "      <td>like bigger screen size easy read books overal...</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>[like, bigger, screen, size, allows, read, boo...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2307 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text split  \\\n",
       "42218    bought media room great faster previous version   val   \n",
       "42220     got wife loves easy read loves fact carry book   val   \n",
       "42221                               every year never run   val   \n",
       "42222  works great watching tv shows plugged right ea...   val   \n",
       "42223  know bluetooth think auxiliary port older spea...   val   \n",
       "...                                                  ...   ...   \n",
       "46896  seems like quality varies batts work great las...   val   \n",
       "46899  easy setup use like picture screen bought 5 ga...   val   \n",
       "46900  duds bought christmas could stick toys one wor...   val   \n",
       "46904  features old rca tablet memory battery power p...   val   \n",
       "46908  like bigger screen size allows read books with...   val   \n",
       "\n",
       "                           trunc_text  \\\n",
       "42218         bought media room great   \n",
       "42220             got wife loves easy   \n",
       "42221            every year never run   \n",
       "42222         works great watching tv   \n",
       "42223  know bluetooth think auxiliary   \n",
       "...                               ...   \n",
       "46896       seems like quality varies   \n",
       "46899             easy setup use like   \n",
       "46900     duds bought christmas could   \n",
       "46904         features old rca tablet   \n",
       "46908         like bigger screen size   \n",
       "\n",
       "                                            gpt_text_gen  jaccard_score  \\\n",
       "42218               bought media room great sound wanted       0.789474   \n",
       "42220                 got wife loves easy use simple set       0.619048   \n",
       "42221         every year never run batteries great price       0.533333   \n",
       "42222  works great watching tv shows netflix amazon p...       0.708333   \n",
       "42223  know bluetooth think auxiliary port since tabl...       0.782609   \n",
       "...                                                  ...            ...   \n",
       "46896          seems like quality varies based needs use       0.772727   \n",
       "46899     easy setup use like asking weather traffic etc       0.739130   \n",
       "46900              duds bought christmas couldnt happier       0.782609   \n",
       "46904  features old rca tablet different brands amazo...       0.727273   \n",
       "46908  like bigger screen size easy read books overal...       0.708333   \n",
       "\n",
       "                                              text_lists  word_count  \n",
       "42218  [bought, media, room, great, faster, previous,...           7  \n",
       "42220  [got, wife, loves, easy, read, loves, fact, ca...           9  \n",
       "42221                          [every, year, never, run]           4  \n",
       "42222  [works, great, watching, tv, shows, plugged, r...           9  \n",
       "42223  [know, bluetooth, think, auxiliary, port, olde...           7  \n",
       "...                                                  ...         ...  \n",
       "46896  [seems, like, quality, varies, batts, work, gr...          12  \n",
       "46899  [easy, setup, use, like, picture, screen, boug...          12  \n",
       "46900  [duds, bought, christmas, could, stick, toys, ...          35  \n",
       "46904  [features, old, rca, tablet, memory, battery, ...          12  \n",
       "46908  [like, bigger, screen, size, allows, read, boo...          13  \n",
       "\n",
       "[2307 rows x 7 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample those with lower than average jaccard similarity score\n",
    "mean_score = data_val.describe()[\"jaccard_score\"][\"mean\"]\n",
    "data_val_low_jac_score = data_val[data_val[\"jaccard_score\"] < mean_score]\n",
    "data_val_low_jac_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bd71681f-f146-436d-8e79-171f0d5f3c8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jaccard_score</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2307.000000</td>\n",
       "      <td>2307.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.706296</td>\n",
       "      <td>16.226701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.092617</td>\n",
       "      <td>19.138406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.055556</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.727273</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.769231</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>401.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       jaccard_score   word_count\n",
       "count    2307.000000  2307.000000\n",
       "mean        0.706296    16.226701\n",
       "std         0.092617    19.138406\n",
       "min         0.055556     1.000000\n",
       "25%         0.666667     7.000000\n",
       "50%         0.727273    11.000000\n",
       "75%         0.769231    19.000000\n",
       "max         0.800000   401.000000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the statistics\n",
    "data_val_low_jac_score.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d56ec839-3056-4b50-a133-4ba4fdb5ebeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: bought media room great faster previous version\n",
      "input_words: bought media room great\n",
      "gpt2_text generated: bought media room great sound wanted\n",
      "\n",
      "\n",
      "Original text: intending buy rechargeables bought mistake work fine though\n",
      "input_words: intending buy rechargeables bought\n",
      "gpt2_text generated: intending buy rechargeables bought amazonbasics use minor devices work great cost savings pretty decent quality\n",
      "\n",
      "\n",
      "Original text: like bigger screen size allows read books without straining eyes allows text displayed\n",
      "input_words: like bigger screen size\n",
      "gpt2_text generated: like bigger screen size easy read books overall satisfied\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Printing some samples\n",
    "view_generated_samples(0, data_val_low_jac_score)\n",
    "view_generated_samples(10, data_val_low_jac_score)\n",
    "view_generated_samples(-1, data_val_low_jac_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90aa7b21-0cba-4332-a7e4-16f1460c2e70",
   "metadata": {},
   "source": [
    "### Overall observation using Jaccard Similarity Score\n",
    "\n",
    "1. The average jaccard similarity score calculated on the validation set is 0.8. This means the generated text on average are only 80% similar to the original text which seems to indicate a pretty good score.\n",
    "2. In general, the jaccard score is higher for given sentences that are shorter in length.\n",
    "3. The limitation with jaccard similiarity:\n",
    "- is it does not capture the magnitude or direction of the vectors and hence it may not reflec the strength of the similarity\n",
    "- Does not consider the order or the context of the words and it may miss semantic variations that could be generated by gpt2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13aa551-7c00-447a-bca5-7179fbfc0200",
   "metadata": {},
   "source": [
    "### ii. Symantic Similarity Search - Word2vec Cosine Similarity\n",
    "\n",
    "One of the pitfalls of using jaccard similarity is it does not take into account the symantic meaning of the sentences. As language, there are many ways to express things and likewise, certain sentences can the same meaning but can be written in a different way. Hence we can make use of the idea of embedding and calculate the cosine similarity (which is the measure of the similarity between two vectors) between the original and gpt generated text. \n",
    "\n",
    "To calcualte the similarity this, we will use a pretrained word2vec model to generate the embeddings of the original text and the gpt2 generated text. Then we will compare the embeddings via cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "81e4e4b1-b8ef-4ded-82a7-a325c7a2416f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "182394f6-fec3-4367-8e6b-d9d1a362dacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "# Create embeddings using simply word2vec\n",
    "def generate_word2vec_embedding(sentence: str):\n",
    "    # generate the average of word embeddings\n",
    "    return nlp(sentence).vector\n",
    "\n",
    "def calculate_cosine_similarity_score(sentence_one: str, sentence_two: str):\n",
    "    # encode the sentences into embeddings\n",
    "    sentence_one_emb = generate_word2vec_embedding(sentence_one)\n",
    "    sentence_two_emb = generate_word2vec_embedding(sentence_two)\n",
    "    \n",
    "    # calculate cosine similarity score\n",
    "    cos_sim_score = 1 - cosine(sentence_one_emb, sentence_two_emb)\n",
    "    return cos_sim_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6010c052-d6a1-4150-a1ab-883d0f993b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load word2vec pretrained model\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5cb9057f-c95f-44c2-9836-d4efdb385f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004839420318603516,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 4691,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3a739af79a44a4c977ee1f253e8e3d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4691 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9147/2717386745.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_val[\"cos_sim_score\"] = data_val.progress_apply(lambda x: calculate_cosine_similarity_score(x[\"text\"], x[\"gpt_text_gen\"]), axis=1)\n"
     ]
    }
   ],
   "source": [
    "# Calculate cosine similarity score\n",
    "data_val[\"cos_sim_score\"] = data_val.progress_apply(lambda x: calculate_cosine_similarity_score(x[\"text\"], x[\"gpt_text_gen\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "55b75be3-4d9d-4e41-aa7b-e804163b841e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jaccard_score</th>\n",
       "      <th>word_count</th>\n",
       "      <th>cos_sim_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4691.000000</td>\n",
       "      <td>4691.000000</td>\n",
       "      <td>4691.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.806629</td>\n",
       "      <td>14.312300</td>\n",
       "      <td>0.782896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.128142</td>\n",
       "      <td>15.933587</td>\n",
       "      <td>0.130124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.055556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.021825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.727273</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.706458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.809524</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.782801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.888889</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.856873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>401.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       jaccard_score   word_count  cos_sim_score\n",
       "count    4691.000000  4691.000000    4691.000000\n",
       "mean        0.806629    14.312300       0.782896\n",
       "std         0.128142    15.933587       0.130124\n",
       "min         0.055556     1.000000       0.021825\n",
       "25%         0.727273     7.000000       0.706458\n",
       "50%         0.809524    10.000000       0.782801\n",
       "75%         0.888889    16.000000       0.856873\n",
       "max         1.000000   401.000000       1.000000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Statistics on cosine similarity\n",
    "data_val.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41faf19f-2e8a-49a1-a423-163b1f2ff0f4",
   "metadata": {},
   "source": [
    "#### Explore samples with higher than average cosine similiarity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6c635fcb-f468-4e2a-a7b3-8a1837dfc66b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>split</th>\n",
       "      <th>trunc_text</th>\n",
       "      <th>gpt_text_gen</th>\n",
       "      <th>jaccard_score</th>\n",
       "      <th>text_lists</th>\n",
       "      <th>word_count</th>\n",
       "      <th>cos_sim_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42220</th>\n",
       "      <td>got wife loves easy read loves fact carry book</td>\n",
       "      <td>val</td>\n",
       "      <td>got wife loves easy</td>\n",
       "      <td>got wife loves easy use simple set</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>[got, wife, loves, easy, read, loves, fact, ca...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.891198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42221</th>\n",
       "      <td>every year never run</td>\n",
       "      <td>val</td>\n",
       "      <td>every year never run</td>\n",
       "      <td>every year never run batteries great price</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>[every, year, never, run]</td>\n",
       "      <td>4</td>\n",
       "      <td>0.796730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42225</th>\n",
       "      <td>great tablet lite portable exceptionally fast ...</td>\n",
       "      <td>val</td>\n",
       "      <td>great tablet lite portable</td>\n",
       "      <td>great tablet lite portable resolution makes pe...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>[great, tablet, lite, portable, exceptionally,...</td>\n",
       "      <td>14</td>\n",
       "      <td>0.790777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42227</th>\n",
       "      <td>love pricing quality always buy amazon batteries</td>\n",
       "      <td>val</td>\n",
       "      <td>love pricing quality always</td>\n",
       "      <td>love pricing quality always order</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>[love, pricing, quality, always, buy, amazon, ...</td>\n",
       "      <td>7</td>\n",
       "      <td>0.801396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42228</th>\n",
       "      <td>keeps busy great tablet always home bored stuc...</td>\n",
       "      <td>val</td>\n",
       "      <td>keeps busy great tablet</td>\n",
       "      <td>keeps busy great tablet money</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>[keeps, busy, great, tablet, always, home, bor...</td>\n",
       "      <td>14</td>\n",
       "      <td>0.812312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46898</th>\n",
       "      <td>friend purchased kindle really impressed ease ...</td>\n",
       "      <td>val</td>\n",
       "      <td>friend purchased kindle really</td>\n",
       "      <td>friend purchased kindle really like setup extr...</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>[friend, purchased, kindle, really, impressed,...</td>\n",
       "      <td>19</td>\n",
       "      <td>0.853455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46902</th>\n",
       "      <td>bit skeptical first purchasing device roku gla...</td>\n",
       "      <td>val</td>\n",
       "      <td>bit skeptical first purchasing</td>\n",
       "      <td>bit skeptical first purchasing amazonbasics pr...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>[bit, skeptical, first, purchasing, device, ro...</td>\n",
       "      <td>22</td>\n",
       "      <td>0.804096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46904</th>\n",
       "      <td>features old rca tablet memory battery power p...</td>\n",
       "      <td>val</td>\n",
       "      <td>features old rca tablet</td>\n",
       "      <td>features old rca tablet different brands amazo...</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>[features, old, rca, tablet, memory, battery, ...</td>\n",
       "      <td>12</td>\n",
       "      <td>0.809305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46905</th>\n",
       "      <td>always happy amazon didnt disappoint work grea...</td>\n",
       "      <td>val</td>\n",
       "      <td>always happy amazon didnt</td>\n",
       "      <td>always happy amazon didnt disappoint job great...</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>[always, happy, amazon, didnt, disappoint, wor...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.947824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46907</th>\n",
       "      <td>bought kids really love</td>\n",
       "      <td>val</td>\n",
       "      <td>bought kids really love</td>\n",
       "      <td>bought kids really love easy use</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[bought, kids, really, love]</td>\n",
       "      <td>4</td>\n",
       "      <td>0.822376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2344 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text split  \\\n",
       "42220     got wife loves easy read loves fact carry book   val   \n",
       "42221                               every year never run   val   \n",
       "42225  great tablet lite portable exceptionally fast ...   val   \n",
       "42227   love pricing quality always buy amazon batteries   val   \n",
       "42228  keeps busy great tablet always home bored stuc...   val   \n",
       "...                                                  ...   ...   \n",
       "46898  friend purchased kindle really impressed ease ...   val   \n",
       "46902  bit skeptical first purchasing device roku gla...   val   \n",
       "46904  features old rca tablet memory battery power p...   val   \n",
       "46905  always happy amazon didnt disappoint work grea...   val   \n",
       "46907                            bought kids really love   val   \n",
       "\n",
       "                           trunc_text  \\\n",
       "42220             got wife loves easy   \n",
       "42221            every year never run   \n",
       "42225      great tablet lite portable   \n",
       "42227     love pricing quality always   \n",
       "42228         keeps busy great tablet   \n",
       "...                               ...   \n",
       "46898  friend purchased kindle really   \n",
       "46902  bit skeptical first purchasing   \n",
       "46904         features old rca tablet   \n",
       "46905       always happy amazon didnt   \n",
       "46907         bought kids really love   \n",
       "\n",
       "                                            gpt_text_gen  jaccard_score  \\\n",
       "42220                 got wife loves easy use simple set       0.619048   \n",
       "42221         every year never run batteries great price       0.533333   \n",
       "42225  great tablet lite portable resolution makes pe...       0.666667   \n",
       "42227                  love pricing quality always order       0.818182   \n",
       "42228                      keeps busy great tablet money       0.695652   \n",
       "...                                                  ...            ...   \n",
       "46898  friend purchased kindle really like setup extr...       0.869565   \n",
       "46902  bit skeptical first purchasing amazonbasics pr...       0.833333   \n",
       "46904  features old rca tablet different brands amazo...       0.727273   \n",
       "46905  always happy amazon didnt disappoint job great...       0.863636   \n",
       "46907                   bought kids really love easy use       1.000000   \n",
       "\n",
       "                                              text_lists  word_count  \\\n",
       "42220  [got, wife, loves, easy, read, loves, fact, ca...           9   \n",
       "42221                          [every, year, never, run]           4   \n",
       "42225  [great, tablet, lite, portable, exceptionally,...          14   \n",
       "42227  [love, pricing, quality, always, buy, amazon, ...           7   \n",
       "42228  [keeps, busy, great, tablet, always, home, bor...          14   \n",
       "...                                                  ...         ...   \n",
       "46898  [friend, purchased, kindle, really, impressed,...          19   \n",
       "46902  [bit, skeptical, first, purchasing, device, ro...          22   \n",
       "46904  [features, old, rca, tablet, memory, battery, ...          12   \n",
       "46905  [always, happy, amazon, didnt, disappoint, wor...           9   \n",
       "46907                       [bought, kids, really, love]           4   \n",
       "\n",
       "       cos_sim_score  \n",
       "42220       0.891198  \n",
       "42221       0.796730  \n",
       "42225       0.790777  \n",
       "42227       0.801396  \n",
       "42228       0.812312  \n",
       "...              ...  \n",
       "46898       0.853455  \n",
       "46902       0.804096  \n",
       "46904       0.809305  \n",
       "46905       0.947824  \n",
       "46907       0.822376  \n",
       "\n",
       "[2344 rows x 8 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample those with higher than average cosine similarity score\n",
    "mean_score = data_val.describe()[\"cos_sim_score\"][\"mean\"]\n",
    "data_val_high_cos_sim_score = data_val[data_val[\"cos_sim_score\"] > mean_score]\n",
    "data_val_high_cos_sim_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "288a04c1-c919-4051-bb42-6ebe97b1d178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jaccard_score</th>\n",
       "      <th>word_count</th>\n",
       "      <th>cos_sim_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2344.000000</td>\n",
       "      <td>2344.000000</td>\n",
       "      <td>2344.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.862033</td>\n",
       "      <td>12.073805</td>\n",
       "      <td>0.882647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.113807</td>\n",
       "      <td>15.427113</td>\n",
       "      <td>0.077448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.428571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.782942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.777778</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.816977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.863636</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.856913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.981396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>401.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       jaccard_score   word_count  cos_sim_score\n",
       "count    2344.000000  2344.000000    2344.000000\n",
       "mean        0.862033    12.073805       0.882647\n",
       "std         0.113807    15.427113       0.077448\n",
       "min         0.428571     1.000000       0.782942\n",
       "25%         0.777778     6.000000       0.816977\n",
       "50%         0.863636     8.000000       0.856913\n",
       "75%         1.000000    13.000000       0.981396\n",
       "max         1.000000   401.000000       1.000000"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_val_high_cos_sim_score.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6808a6c2-0a08-4bec-b9b8-efa746b77c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: got wife loves easy read loves fact carry book\n",
      "input_words: got wife loves easy\n",
      "gpt2_text generated: got wife loves easy use simple set\n",
      "\n",
      "\n",
      "Original text: smart amazon echo enjoying theses amazon echo life much easy excellent amazon echo\n",
      "input_words: smart amazon echo enjoying\n",
      "gpt2_text generated: smart amazon echo enjoying far great device\n",
      "\n",
      "\n",
      "Original text: bought kids really love\n",
      "input_words: bought kids really love\n",
      "gpt2_text generated: bought kids really love easy use\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Printing some samples\n",
    "view_generated_samples(0, data_val_high_cos_sim_score)\n",
    "view_generated_samples(10, data_val_high_cos_sim_score)\n",
    "view_generated_samples(-1, data_val_high_cos_sim_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de66edfa-c6c6-4024-a774-4dbaa622302c",
   "metadata": {},
   "source": [
    "#### Explore samples with lower than average cosine similiarity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "65941cc6-e587-47b7-82af-aea5e44bf4fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>split</th>\n",
       "      <th>trunc_text</th>\n",
       "      <th>gpt_text_gen</th>\n",
       "      <th>jaccard_score</th>\n",
       "      <th>text_lists</th>\n",
       "      <th>word_count</th>\n",
       "      <th>cos_sim_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42218</th>\n",
       "      <td>bought media room great faster previous version</td>\n",
       "      <td>val</td>\n",
       "      <td>bought media room great</td>\n",
       "      <td>bought media room great sound wanted</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>[bought, media, room, great, faster, previous,...</td>\n",
       "      <td>7</td>\n",
       "      <td>0.744388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42219</th>\n",
       "      <td>second kindle would lost without convenient th...</td>\n",
       "      <td>val</td>\n",
       "      <td>second kindle would lost</td>\n",
       "      <td>second kindle would lost without kindles kinde...</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>[second, kindle, would, lost, without, conveni...</td>\n",
       "      <td>13</td>\n",
       "      <td>0.660017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42222</th>\n",
       "      <td>works great watching tv shows plugged right ea...</td>\n",
       "      <td>val</td>\n",
       "      <td>works great watching tv</td>\n",
       "      <td>works great watching tv shows netflix amazon p...</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>[works, great, watching, tv, shows, plugged, r...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.781023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42223</th>\n",
       "      <td>know bluetooth think auxiliary port older spea...</td>\n",
       "      <td>val</td>\n",
       "      <td>know bluetooth think auxiliary</td>\n",
       "      <td>know bluetooth think auxiliary port since tabl...</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>[know, bluetooth, think, auxiliary, port, olde...</td>\n",
       "      <td>7</td>\n",
       "      <td>0.733885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42224</th>\n",
       "      <td>good price batteries seem good quality price r...</td>\n",
       "      <td>val</td>\n",
       "      <td>good price batteries seem</td>\n",
       "      <td>good price batteries seem work well name brand...</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>[good, price, batteries, seem, good, quality, ...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.779305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46900</th>\n",
       "      <td>duds bought christmas could stick toys one wor...</td>\n",
       "      <td>val</td>\n",
       "      <td>duds bought christmas could</td>\n",
       "      <td>duds bought christmas couldnt happier</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>[duds, bought, christmas, could, stick, toys, ...</td>\n",
       "      <td>35</td>\n",
       "      <td>0.609053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46901</th>\n",
       "      <td>really quick service glad discover amazon carr...</td>\n",
       "      <td>val</td>\n",
       "      <td>really quick service glad</td>\n",
       "      <td>really quick service glad bought item</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>[really, quick, service, glad, discover, amazo...</td>\n",
       "      <td>12</td>\n",
       "      <td>0.748612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46903</th>\n",
       "      <td>wife loves neat works info endless music optio...</td>\n",
       "      <td>val</td>\n",
       "      <td>wife loves neat works</td>\n",
       "      <td>wife loves neat works videos well amazon prime</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>[wife, loves, neat, works, info, endless, musi...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.641326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46906</th>\n",
       "      <td>im giving three stars havent used much watch s...</td>\n",
       "      <td>val</td>\n",
       "      <td>im giving three stars</td>\n",
       "      <td>im giving three stars instead five seems silly...</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>[im, giving, three, stars, havent, used, much,...</td>\n",
       "      <td>34</td>\n",
       "      <td>0.664652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46908</th>\n",
       "      <td>like bigger screen size allows read books with...</td>\n",
       "      <td>val</td>\n",
       "      <td>like bigger screen size</td>\n",
       "      <td>like bigger screen size easy read books overal...</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>[like, bigger, screen, size, allows, read, boo...</td>\n",
       "      <td>13</td>\n",
       "      <td>0.541695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2347 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text split  \\\n",
       "42218    bought media room great faster previous version   val   \n",
       "42219  second kindle would lost without convenient th...   val   \n",
       "42222  works great watching tv shows plugged right ea...   val   \n",
       "42223  know bluetooth think auxiliary port older spea...   val   \n",
       "42224  good price batteries seem good quality price r...   val   \n",
       "...                                                  ...   ...   \n",
       "46900  duds bought christmas could stick toys one wor...   val   \n",
       "46901  really quick service glad discover amazon carr...   val   \n",
       "46903  wife loves neat works info endless music optio...   val   \n",
       "46906  im giving three stars havent used much watch s...   val   \n",
       "46908  like bigger screen size allows read books with...   val   \n",
       "\n",
       "                           trunc_text  \\\n",
       "42218         bought media room great   \n",
       "42219        second kindle would lost   \n",
       "42222         works great watching tv   \n",
       "42223  know bluetooth think auxiliary   \n",
       "42224       good price batteries seem   \n",
       "...                               ...   \n",
       "46900     duds bought christmas could   \n",
       "46901       really quick service glad   \n",
       "46903           wife loves neat works   \n",
       "46906           im giving three stars   \n",
       "46908         like bigger screen size   \n",
       "\n",
       "                                            gpt_text_gen  jaccard_score  \\\n",
       "42218               bought media room great sound wanted       0.789474   \n",
       "42219  second kindle would lost without kindles kinde...       0.904762   \n",
       "42222  works great watching tv shows netflix amazon p...       0.708333   \n",
       "42223  know bluetooth think auxiliary port since tabl...       0.782609   \n",
       "42224  good price batteries seem work well name brand...       0.739130   \n",
       "...                                                  ...            ...   \n",
       "46900              duds bought christmas couldnt happier       0.782609   \n",
       "46901              really quick service glad bought item       0.909091   \n",
       "46903     wife loves neat works videos well amazon prime       0.809524   \n",
       "46906  im giving three stars instead five seems silly...       0.875000   \n",
       "46908  like bigger screen size easy read books overal...       0.708333   \n",
       "\n",
       "                                              text_lists  word_count  \\\n",
       "42218  [bought, media, room, great, faster, previous,...           7   \n",
       "42219  [second, kindle, would, lost, without, conveni...          13   \n",
       "42222  [works, great, watching, tv, shows, plugged, r...           9   \n",
       "42223  [know, bluetooth, think, auxiliary, port, olde...           7   \n",
       "42224  [good, price, batteries, seem, good, quality, ...           8   \n",
       "...                                                  ...         ...   \n",
       "46900  [duds, bought, christmas, could, stick, toys, ...          35   \n",
       "46901  [really, quick, service, glad, discover, amazo...          12   \n",
       "46903  [wife, loves, neat, works, info, endless, musi...          10   \n",
       "46906  [im, giving, three, stars, havent, used, much,...          34   \n",
       "46908  [like, bigger, screen, size, allows, read, boo...          13   \n",
       "\n",
       "       cos_sim_score  \n",
       "42218       0.744388  \n",
       "42219       0.660017  \n",
       "42222       0.781023  \n",
       "42223       0.733885  \n",
       "42224       0.779305  \n",
       "...              ...  \n",
       "46900       0.609053  \n",
       "46901       0.748612  \n",
       "46903       0.641326  \n",
       "46906       0.664652  \n",
       "46908       0.541695  \n",
       "\n",
       "[2347 rows x 8 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample those with lower than average cosine similarity score\n",
    "mean_score = data_val.describe()[\"cos_sim_score\"][\"mean\"]\n",
    "data_val_low_cos_sim_score = data_val[data_val[\"cos_sim_score\"] < mean_score]\n",
    "data_val_low_cos_sim_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "40f1b8b6-2610-48e6-8d6b-5e78b87ec022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jaccard_score</th>\n",
       "      <th>word_count</th>\n",
       "      <th>cos_sim_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2347.000000</td>\n",
       "      <td>2347.000000</td>\n",
       "      <td>2347.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.751296</td>\n",
       "      <td>16.547934</td>\n",
       "      <td>0.683272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.117308</td>\n",
       "      <td>16.119669</td>\n",
       "      <td>0.089379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.055556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.021825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.695652</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.643253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.764706</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.706483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.826087</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.748282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>163.000000</td>\n",
       "      <td>0.782855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       jaccard_score   word_count  cos_sim_score\n",
       "count    2347.000000  2347.000000    2347.000000\n",
       "mean        0.751296    16.547934       0.683272\n",
       "std         0.117308    16.119669       0.089379\n",
       "min         0.055556     1.000000       0.021825\n",
       "25%         0.695652     8.000000       0.643253\n",
       "50%         0.764706    12.000000       0.706483\n",
       "75%         0.826087    20.000000       0.748282\n",
       "max         1.000000   163.000000       0.782855"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_val_low_cos_sim_score.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b1571ded-5833-4110-991f-671dc791bcfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: bought media room great faster previous version\n",
      "input_words: bought media room great\n",
      "gpt2_text generated: bought media room great sound wanted\n",
      "\n",
      "\n",
      "Original text: love stick kinda slow navigating one much faster going use cancel cable told cable company wanted cancel going stream everything cut bundle cost 100 kept cable also still use firetv alot\n",
      "input_words: love stick kinda slow\n",
      "gpt2_text generated: love stick kinda slow navigating used voice search\n",
      "\n",
      "\n",
      "Original text: im giving three stars havent used much watch shows moviesive aprox month sometimes screen goes blank idea whyis tabletor maybe appclueless im making big deal bought black friday money waste dont think id buy\n",
      "input_words: im giving three stars\n",
      "gpt2_text generated: im giving three stars instead five seems silly restrictions used many ways cut cable bill\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Printing some samples\n",
    "view_generated_samples(0, data_val_low_cos_sim_score)\n",
    "view_generated_samples(20, data_val_low_cos_sim_score)\n",
    "view_generated_samples(-2, data_val_low_cos_sim_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eff30c4-a665-48e3-8e31-1ae7afe9e64f",
   "metadata": {},
   "source": [
    "### Overall observations on Cosine Similarity Score\n",
    "1. The average cosine similarity score between the original and gpt2 generated text on validation data is around 0.78 with a min score of -0.05 and maximum score 1.0\n",
    "2. Similar to jaccard similarity score, the cosine similarity score of the gpt2 generated text is higher when the original sentences have less words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c88c00f-f9df-45e9-9d91-c0d62f97f4c1",
   "metadata": {},
   "source": [
    "## Improvements\n",
    "1. Overall we can see the generated text are not quite identicle to the original text. This is expected since we only trained the model on 6 epochs and the loss had not yet converged.\n",
    "2. Splitting the dataset -> perhaps we can try to split the data to ensure we have a representative dataset. For example we can try using sentence transformer model to generate the embeddings, then perform clustering to group the data. Then we systematically sample data for each of the groups rather than randomly splitting.\n",
    "3. Maybe we can try to retrain the model using a reviews dataset first and then use the current dataset and fine tune it.\n",
    "4. Using pretraind word2vec may not be the best way to measure and evaluate the quality of the text generated since its a quantitative approach. Perhaps incorporating a more qualitiative approach too might be needed to fully evaluate the gpt2 generated text - coherence etc, BLEU or ROGUE\n",
    "5. Using sentence transformers to generate embeddings rather than word2vec."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e69d9a-cc1c-4eac-810a-995ce53555f7",
   "metadata": {},
   "source": [
    "## END"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "text-gen",
   "name": "pytorch-gpu.1-11.m93",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-11:m93"
  },
  "kernelspec": {
   "display_name": "text-gen",
   "language": "python",
   "name": "text-gen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
